{"nbformat":4,"nbformat_minor":0,"metadata":{"kernel_info":{"name":"Weblab"},"language_info":{"name":"javascript"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["# Making predictions from 2D data\n\nIn this example we will train a simple neural network to make predictions from given 2D data. It is taken from the official [tensorflow examples](https://codelabs.developers.google.com/codelabs/tfjs-training-regression). The network is trained on 2D data related to \"Horsepower\" and \"Miles per Gallon\" of cars. The goal is for the network to give predictions for the \"Miles per Gallon\" given the \"Horsepower\" of a car.\nBefore we start with the example, we need to make sure that the required libraries are imported into the notebook. For that we can use the javascript import statement to import \"tensorflowjs\" and \"plotly\":"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h1>Making predictions from 2D data</h1>\n<p>In this example we will train a simple neural network to make predictions from given 2D data. It is taken from the official <a href=\"https://codelabs.developers.google.com/codelabs/tfjs-training-regression\">tensorflow examples</a>. The network is trained on 2D data related to &quot;Horsepower&quot; and &quot;Miles per Gallon&quot; of cars. The goal is for the network to give predictions for the &quot;Miles per Gallon&quot; given the &quot;Horsepower&quot; of a car.\nBefore we start with the example, we need to make sure that the required libraries are imported into the notebook. For that we can use the javascript import statement to import &quot;tensorflowjs&quot; and &quot;plotly&quot;:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["import * as tf from '@tensorflow/tfjs';\nimport {default as plotly} from \"plotly.js-cartesian-esm\";\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Load and format the input data\n\nThe first step is to load and process the data for the machine learning model. The dataset that we are going to use contains a lot of data concerning different cars. Our goal is to look at the data related to \"Horsepower\" and \"Miles per Gallon\" and find a relation between them. Let us first load the data and get a feeling for what we are dealing with. For that we fetch the data from a given url and read the contained JSON data from it. Be aware of the `await` keyword. It is required to obtain values from [asynchronous functions](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await) like `fetch`."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Load and format the input data</h2>\n<p>The first step is to load and process the data for the machine learning model. The dataset that we are going to use contains a lot of data concerning different cars. Our goal is to look at the data related to &quot;Horsepower&quot; and &quot;Miles per Gallon&quot; and find a relation between them. Let us first load the data and get a feeling for what we are dealing with. For that we fetch the data from a given url and read the contained JSON data from it. Be aware of the <code>await</code> keyword. It is required to obtain values from <a href=\"https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await\">asynchronous functions</a> like <code>fetch</code>.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const carsDataResponse = await fetch('https://storage.googleapis.com/tfjs-tutorials/carsData.json');  \nconst carsData = await carsDataResponse.json();\n\ncarsData"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["In the next step we want to clean the data. That means we will only keep the entries related to the \"Miles per Gallon\" and \"Horsepower\". Additionally we make sure that all entries have valid values."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>In the next step we want to clean the data. That means we will only keep the entries related to the &quot;Miles per Gallon&quot; and &quot;Horsepower&quot;. Additionally we make sure that all entries have valid values.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const cleaned = carsData.map(car => ({\n  mpg: car.Miles_per_Gallon,\n  horsepower: car.Horsepower,\n}))\n.filter(car => (car.mpg != null && car.horsepower != null));\n\ncleaned"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["It is generally a good idea to visualize your data to get a better understanding of it. It will help you to find a structure in the data that a model can learn. Let's take advantage of the interactive capabilities of the notebook and display the data. To do this, we use the `plotly-js` library.\nThe following cell will create a `div` element into which we will plot the data."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>It is generally a good idea to visualize your data to get a better understanding of it. It will help you to find a structure in the data that a model can learn. Let's take advantage of the interactive capabilities of the notebook and display the data. To do this, we use the <code>plotly-js</code> library.\nThe following cell will create a <code>div</code> element into which we will plot the data.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let scatter = document.createElement(\"div\");\nscatter.id = \"scatter\"\nscatter"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["We can then plot the data as follows:"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>We can then plot the data as follows:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let values = {x:[], y:[], type: \"scatter\", mode: \"markers\", name:\"InputData\"};\n\nfor (const val of cleaned) {\n  values.x.push(val.horsepower);\n  values.y.push(val.mpg)\n}\n\nplotly.newPlot(\"scatter\",[values],{xaxis: {title: \"Horsepower\"}, yaxis: {title: \"Miles per gallon\"}})"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["The figure shows the data displayed as \"Miles per Gallon\" over \"Horsepower\". We can see from the plot that there is a negative correlation between the horsepower and the MPG. As the horsepower goes up the miles per gallon go down."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>The figure shows the data displayed as &quot;Miles per Gallon&quot; over &quot;Horsepower&quot;. We can see from the plot that there is a negative correlation between the horsepower and the MPG. As the horsepower goes up the miles per gallon go down.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["### Define the task\n\nThe goal of this example is to train a model to take in __one__ number (horsepower) and predict __one__ number (miles per gallon). The model will be trained with the available data. This is called __Supervised learning__, since we have the correct values for the input data."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h3>Define the task</h3>\n<p>The goal of this example is to train a model to take in <strong>one</strong> number (horsepower) and predict <strong>one</strong> number (miles per gallon). The model will be trained with the available data. This is called <strong>Supervised learning</strong>, since we have the correct values for the input data.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["## Define the model architecture\n\nIn this example we are training a neural network. The model architecture describes how the neural network is structured. When using neural networks, the algorithm is a set of layers of neurons with \"weights\" governing their output. The training process learns the ideal values for those weights.\n\nFor this example we need a relatively simple model. We will use a sequential model where the inputs flow straight to the outputs. Lets instantiate the model with the following command:"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Define the model architecture</h2>\n<p>In this example we are training a neural network. The model architecture describes how the neural network is structured. When using neural networks, the algorithm is a set of layers of neurons with &quot;weights&quot; governing their output. The training process learns the ideal values for those weights.</p>\n<p>For this example we need a relatively simple model. We will use a sequential model where the inputs flow straight to the outputs. Lets instantiate the model with the following command:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const model = tf.sequential();"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["### Add layers\n\nNeural networks always need an input and ouptut layer that fits the requirements of the problem. In our case we have one input variable and one output variable. Consequenlty, we need to define an input layer with dimension 1. The following command adds an input layer with `inputShape=[1]` to our neural network."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h3>Add layers</h3>\n<p>Neural networks always need an input and ouptut layer that fits the requirements of the problem. In our case we have one input variable and one output variable. Consequenlty, we need to define an input layer with dimension 1. The following command adds an input layer with <code>inputShape=[1]</code> to our neural network.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["model.add(tf.layers.dense({inputShape: [1], units: 1, useBias: true}));"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["The input layer is directly connected to `dense` layers. A dense layers multiplies its input by a (weight) matrix and then adds a (bias) number. The parameter `units` sets the number of neurons.\n\nIn this example we will use a second dense layer with 8 neurons."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>The input layer is directly connected to <code>dense</code> layers. A dense layers multiplies its input by a (weight) matrix and then adds a (bias) number. The parameter <code>units</code> sets the number of neurons.</p>\n<p>In this example we will use a second dense layer with 8 neurons.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["model.add(tf.layers.dense({units: 8, activation: 'relu', useBias: true}));"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Finally we create our ouput layer with the following command: "],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Finally we create our ouput layer with the following command:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["model.add(tf.layers.dense({units: 1}));"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Setting `units` to `1` makes sure we have only one output variable. We can have a look at the model by printing it to the browser console."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Setting <code>units</code> to <code>1</code> makes sure we have only one output variable. We can have a look at the model by printing it to the browser console.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["model.summary()"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Prepare the data for training\n\nTo be able to use the data for training, we have to process it first. Depending on your application it is a good idea to shuffle your data before you train your network. This is done with the following command:"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Prepare the data for training</h2>\n<p>To be able to use the data for training, we have to process it first. Depending on your application it is a good idea to shuffle your data before you train your network. This is done with the following command:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["tf.util.shuffle(cleaned);"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Additionally we will convert the data into tensors to obtain a better performance."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Additionally we will convert the data into tensors to obtain a better performance.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const inputs = cleaned.map(d => d.horsepower)\nconst labels = cleaned.map(d => d.mpg);\n\nconst inputTensor = tf.tensor2d(inputs, [inputs.length, 1]);\nconst labelTensor = tf.tensor2d(labels, [labels.length, 1]);"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["For training it is often helpful to normalize the inputs such that all values lie in between *0-1*. To use the \"Min-Max\" scaling we first calculate the minimum and maximum values of our Tensors."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>For training it is often helpful to normalize the inputs such that all values lie in between <em>0-1</em>. To use the &quot;Min-Max&quot; scaling we first calculate the minimum and maximum values of our Tensors.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const inputMax = inputTensor.max();\nconst inputMin = inputTensor.min();  \nconst labelMax = labelTensor.max();\nconst labelMin = labelTensor.min();\n\nconst normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));\nconst normalizedLabels = labelTensor.sub(labelMin).div(labelMax.sub(labelMin));"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Train the model\n\nWith the model architecture defined and the data stored as \"tensors\", we can start training our model. To do that we have to \"compile\" the defined model. For the compilation a couple of very important things have to be specified:\n\n- __optimizer__: the optimizer governs the change in the weights as the model is trained with the input data. There are many different optimizers available in tensorflow. Check out the [documentation](https://js.tensorflow.org/api/latest/) for more details.\n- __loss__: the loss function is a measure of how well the model is learning the subsets of data it is trained with.  The `meanSquaredError` is a very common choice.\n\n "],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Train the model</h2>\n<p>With the model architecture defined and the data stored as &quot;tensors&quot;, we can start training our model. To do that we have to &quot;compile&quot; the defined model. For the compilation a couple of very important things have to be specified:</p>\n<ul>\n<li><strong>optimizer</strong>: the optimizer governs the change in the weights as the model is trained with the input data. There are many different optimizers available in tensorflow. Check out the <a href=\"https://js.tensorflow.org/api/latest/\">documentation</a> for more details.</li>\n<li><strong>loss</strong>: the loss function is a measure of how well the model is learning the subsets of data it is trained with.  The <code>meanSquaredError</code> is a very common choice.</li>\n</ul>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["// Prepare the model for training.  \nmodel.compile({\n  optimizer: tf.train.adam(),\n  loss: tf.losses.meanSquaredError,\n  metrics: ['mse'],\n});"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Additionally we have to define the batchsize and the number of epochs used:\n- __batchsize__: refers to the size of data subsets the model will see on each iteration of training. Common batchsizes tend to be in the range of 32-512.\n- __epochs__: refers to the number of times the model is going to look at the entire dataset that you provide it. "],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Additionally we have to define the batchsize and the number of epochs used:</p>\n<ul>\n<li><strong>batchsize</strong>: refers to the size of data subsets the model will see on each iteration of training. Common batchsizes tend to be in the range of 32-512.</li>\n<li><strong>epochs</strong>: refers to the number of times the model is going to look at the entire dataset that you provide it.</li>\n</ul>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const batchSize = 32;\nconst epochs = 50;"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Now we are actually ready to train the model. To monitor the training process will will first create a chart into which we will plot the loss function during training."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Now we are actually ready to train the model. To monitor the training process will will first create a chart into which we will plot the loss function during training.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let monitor = document.createElement(\"div\")\nmonitor.id = \"monitor\"\nmonitor"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let lossData = {x: [], y: [], type: \"scatter\", mode: \"lines\"}\n\nplotly.newPlot(\"monitor\",[lossData], {xaxis: {title: \"Epochs\"}, yaxis: {title: \"Loss function\"}})"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Now that the plot is defined, we can start the training process."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Now that the plot is defined, we can start the training process.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["await model.fit(normalizedInputs, normalizedLabels, {\n  batchSize: batchSize,\n  epochs: epochs,\n  shuffle: true,\n  callbacks: [{onEpochEnd: (epoch, logs) => {\n    lossData.x.push(epoch)\n    lossData.y.push(logs.loss)\n    plotly.redraw(\"monitor\")\n    return console.log(epoch, logs.loss)\n  }}]\n});\n\"Done Training\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Lets open the visor and start the training process. The callbacks created earlier will update the plots for the `loss` and `mse` metric. We can see that both are going down with the training."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Lets open the visor and start the training process. The callbacks created earlier will update the plots for the <code>loss</code> and <code>mse</code> metric. We can see that both are going down with the training.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["## Make predictions\n\nNow that we've trained the model, lets make some predictions! For that we'll have a look at the predictions from low to high horsepowers. However, we trained our model with normalized data. Which means that we first need to obtain our predictions with normalized data and \"un-normalize\" them afterwards. We create a tensor with *100* entries from *0-1* as out input for the prediction."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Make predictions</h2>\n<p>Now that we've trained the model, lets make some predictions! For that we'll have a look at the predictions from low to high horsepowers. However, we trained our model with normalized data. Which means that we first need to obtain our predictions with normalized data and &quot;un-normalize&quot; them afterwards. We create a tensor with <em>100</em> entries from <em>0-1</em> as out input for the prediction.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const xs = tf.linspace(0, 1, 100); "],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["From that we can calculate our normalized predictions."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>From that we can calculate our normalized predictions.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const preds = model.predict(xs.reshape([100, 1]));"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["In order to \"un-normalize\" the input, we scale the input tensor to fit the range between the minimum and maximum horsepower values. To \"un-normalize\" the predictions, we scale them to fit the range between the minimum and maximum \"Miles per Gallon\" values. \n\nThe method `arraySync()` obtains a regular Javascript `Array` from a tensor. We transform the tensors because we can then process them in Javascript."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>In order to &quot;un-normalize&quot; the input, we scale the input tensor to fit the range between the minimum and maximum horsepower values. To &quot;un-normalize&quot; the predictions, we scale them to fit the range between the minimum and maximum &quot;Miles per Gallon&quot; values.</p>\n<p>The method <code>arraySync()</code> obtains a regular Javascript <code>Array</code> from a tensor. We transform the tensors because we can then process them in Javascript.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["const unNormXs = xs\n  .mul(inputMax.sub(inputMin))\n  .add(inputMin);\n    \nconst unNormPreds = preds\n  .mul(labelMax.sub(labelMin))\n  .add(labelMin);\n\nconst xs = unNormXs.arraySync()\nconst preds = unNormPreds.arraySync().map(x => {return x[0]})"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Lets have a look how our predictions compare to the original data. For that let us first create a div Element and then plot the data."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Lets have a look how our predictions compare to the original data. For that let us first create a div Element and then plot the data.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let comparison = document.createElement(\"div\")\ncomparison.id = \"comparison\"\ncomparison"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let predictions = {x: xs, y: preds, type: \"scatter\", mode: \"lines\", name: \"Predictions\"}\n\nplotly.newPlot(\"comparison\", [values, predictions], {xaxis: {title: \"Horsepower\"}, yaxis: {title: \"Miles per gallon\"}})"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Bonus\n\nTo be honest our predictions could be better. Play around with the model architecture and see if you can improve the predictions. A couple of things you could try:\n\n- change the number of `epochs`\n- change the number of `units` in the hidden layer\n- change the number of hidden layers between the first hidden layer and the output layer\n- change the activation function\n\nHave fun!"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Bonus</h2>\n<p>To be honest our predictions could be better. Play around with the model architecture and see if you can improve the predictions. A couple of things you could try:</p>\n<ul>\n<li>change the number of <code>epochs</code></li>\n<li>change the number of <code>units</code> in the hidden layer</li>\n<li>change the number of hidden layers between the first hidden layer and the output layer</li>\n<li>change the activation function</li>\n</ul>\n<p>Have fun!</p>\n"}}]}]}
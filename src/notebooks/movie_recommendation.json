{"nbformat":4,"nbformat_minor":0,"metadata":{"kernel_info":{"name":"Weblab"},"language_info":{"name":"javascript"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["# Collaborative filtering for Movie recommendations\n\nThe aim of this tutorial is to train a neural network to give movie recommendations to users based on their ratings of movies they have already watched. \nTherefore we will create a model that uses the [Collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering) technique to make those predictions based on known preferences from other users.\nThe required data for training the model is taken from the [movielens dataset](https://grouplens.org/datasets/movielens/).\nThis example is taken from the official [keras examples](https://keras.io/examples/structured_data/collaborative_filtering_movielens/).\n"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h1>Collaborative filtering for Movie recommendations</h1>\n<p>The aim of this tutorial is to train a neural network to give movie recommendations to users based on their ratings of movies they have already watched.\nTherefore we will create a model that uses the <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">Collaborative filtering</a> technique to make those predictions based on known preferences from other users.\nThe required data for training the model is taken from the <a href=\"https://grouplens.org/datasets/movielens/\">movielens dataset</a>.\nThis example is taken from the official <a href=\"https://keras.io/examples/structured_data/collaborative_filtering_movielens/\">keras examples</a>.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["## Imports\n\nFirst off, we import all required packages for machine learning, decompression, plotting and data manipulation."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Imports</h2>\n<p>First off, we import all required packages for machine learning, decompression, plotting and data manipulation.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["import * as tf from \"@tensorflow/tfjs\"\nimport * as fflate from 'fflate';\nimport * as papaparse from 'papaparse';\nimport {default as plotly} from \"plotly.js-cartesian-esm\"\nimport {DataFrame} from 'https://cdn.jsdelivr.net/npm/@weblab-notebook/danfojs@1.0.2/lib/bundle-esm.js'\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing the data\n\nAs the next step we require the data for training and validation. We can download the compressed dataset from the following url:"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Preprocessing the data</h2>\n<p>As the next step we require the data for training and validation. We can download the compressed dataset from the following url:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let compressed = new Uint8Array(await fetch(\"https://storage.googleapis.com/weblab_datasets/movielens-2018-small.zip\").then(\n  response => response.arrayBuffer()\n));\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Let us then decompress the dataset."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Let us then decompress the dataset.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let decompressed = fflate.unzipSync(compressed,{\n  filter: (file) => {\n    file.name.endsWith('.csv');\n  }\n});\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Next, we will read the data from the `movies.csv` and the `ratings.csv` file.\n\nThe data in the `movies.csv` file has the columns: `movieId, title, genres`\n\nThe data in the `ratings.csv` file has the columns: `userId, movieId, rating, timestamp`"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Next, we will read the data from the <code>movies.csv</code> and the <code>ratings.csv</code> file.</p>\n<p>The data in the <code>movies.csv</code> file has the columns: <code>movieId, title, genres</code></p>\n<p>The data in the <code>ratings.csv</code> file has the columns: <code>userId, movieId, rating, timestamp</code></p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let utf8decoder = new TextDecoder()\n\nlet movies = papaparse.parse(utf8decoder.decode(decompressed[\"ml-latest-small/movies.csv\"]), {header: true, skipEmptyLines: true}).data\n\nlet ratings = papaparse.parse(utf8decoder.decode(decompressed[\"ml-latest-small/ratings.csv\"]), {header: true, skipEmptyLines: true}).data\n\nratings[0]"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["To make the manipulation of the data a bit easier let's create a danfo dataframe for the ratings."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>To make the manipulation of the data a bit easier let's create a danfo dataframe for the ratings.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let df = new DataFrame(ratings)\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["In order for the neural network to distinguish different users or movies, they are referred to by their indices. Sadly, the `Ids` from the input dataset contain gaps and cannot be used. Consequently, we will create our own indices for both users and movies.\n\nIn the next cell we will collect the unique indices present in the dataset and than map to our own representation."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>In order for the neural network to distinguish different users or movies, they are referred to by their indices. Sadly, the <code>Ids</code> from the input dataset contain gaps and cannot be used. Consequently, we will create our own indices for both users and movies.</p>\n<p>In the next cell we will collect the unique indices present in the dataset and than map to our own representation.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let userIds = df[\"userId\"].unique().values;\nlet user2encoded = userIds.reduce((acc,x,i)=> {acc[x] = i; return acc},{})\nlet encoded2user = userIds.reduce((acc,x,i)=> {acc[i] = x; return acc},{})\n\nlet movieIds = df[\"movieId\"].unique().values;\nlet movie2encoded = movieIds.reduce((acc,x,i)=> {acc[x] = i; return acc},{})\nlet encoded2movie = movieIds.reduce((acc,x,i)=> {acc[i] = x; return acc},{})\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Additionally we have to add our indices to the dataframe."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Additionally we have to add our indices to the dataframe.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["df.addColumn(\"user\", df[\"userId\"].map(user2encoded), { inplace: true })\ndf.addColumn(\"movie\", df[\"movieId\"].map(movie2encoded), { inplace: true })\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Finally, let's collect some information like the number of users, the number of movies and minimum and maximum rating from our dataset."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Finally, let's collect some information like the number of users, the number of movies and minimum and maximum rating from our dataset.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let nUsers = userIds.length;\nlet nMovies = movieIds.length;\n\nlet minRating = df[\"rating\"].min();\nlet maxRating = df[\"rating\"].max();\n\nnUsers"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Prepare training and validation data\n\nBefore we can pass the data to our training algorithm, it has to be put into the right form. Our network is supposed to be passed a user and a movie and then predict the rating. Therefore our input consists of two tensors: one that contains the user indices and one that contains the movie indices.\nThe output tensor has to contain the ratings for the movies.\n\nBefore the creation of the input and output tensors, the data has to be shuffled."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Prepare training and validation data</h2>\n<p>Before we can pass the data to our training algorithm, it has to be put into the right form. Our network is supposed to be passed a user and a movie and then predict the rating. Therefore our input consists of two tensors: one that contains the user indices and one that contains the movie indices.\nThe output tensor has to contain the ratings for the movies.</p>\n<p>Before the creation of the input and output tensors, the data has to be shuffled.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let shuffle = await df.sample(ratings.length)\n\nlet x = [shuffle[\"user\"].tensor.expandDims(1),shuffle[\"movie\"].tensor.expandDims(1)]\n\nlet y = shuffle[\"rating\"].apply(x => (x - minRating)/(maxRating - minRating)).tensor.expandDims(1)\n\ny.shape"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Model Architecture\n\nNow that the data is ready to be used, we can start building the model.\nWith tensorflow.js it is very convenient to use the Keras API that uses layers as an abstraction to build your model.\nSo in the next step we will create the different layers that we will need later."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Model Architecture</h2>\n<p>Now that the data is ready to be used, we can start building the model.\nWith tensorflow.js it is very convenient to use the Keras API that uses layers as an abstraction to build your model.\nSo in the next step we will create the different layers that we will need later.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["### Define layers\n\nFirstly, we have to specify the inputs to our model. As mentioned before, we have one input for the user index and one input for the movie index. Since both are scalar values we set the shape to `[1]`. For performance reasons the algorithm typically groups multiple inputs together to form a batch. So the input will be extended by a batch dimension to have the shape `[batchSize, 1]`. But the algorithm will do this automatically.\n\nThe datatype of our inputs is 32-bit integers. "],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h3>Define layers</h3>\n<p>Firstly, we have to specify the inputs to our model. As mentioned before, we have one input for the user index and one input for the movie index. Since both are scalar values we set the shape to <code>[1]</code>. For performance reasons the algorithm typically groups multiple inputs together to form a batch. So the input will be extended by a batch dimension to have the shape <code>[batchSize, 1]</code>. But the algorithm will do this automatically.</p>\n<p>The datatype of our inputs is 32-bit integers.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let userInput = tf.layers.input({shape: [1], dtype: \"int32\"});\nlet movieInput = tf.layers.input({shape: [1], dtype: \"int32\"});\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["The next layers are embedding layers, which play a very crucial role for the neural network. They turn the index, which has no mathematical structure, into a vector representation that our model can understand. The goal is to have a representation for users and movies that posses certain mathematical properties. This way one can measure the \"similarity\" between movies. Movies that are rated similar by each user should have a similar embedding representation.\n\nFor our example we choose the lengths of our embedding vectors to be `64`.\n\nWith that we create an embedding layer for our users and movies."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>The next layers are embedding layers, which play a very crucial role for the neural network. They turn the index, which has no mathematical structure, into a vector representation that our model can understand. The goal is to have a representation for users and movies that posses certain mathematical properties. This way one can measure the &quot;similarity&quot; between movies. Movies that are rated similar by each user should have a similar embedding representation.</p>\n<p>For our example we choose the lengths of our embedding vectors to be <code>64</code>.</p>\n<p>With that we create an embedding layer for our users and movies.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let embeddingSize = 64;\n\nlet userEmbedding = tf.layers.embedding({inputDim: nUsers, inputLength: 1, outputDim: embeddingSize, embeddingsInitializer: \"heNormal\"});\n\nlet movieEmbedding = tf.layers.embedding({inputDim: nMovies, inputLength: 1, outputDim: embeddingSize, embeddingsInitializer: \"heNormal\"});\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Additionally, let's create a bias layer for our users and movies."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Additionally, let's create a bias layer for our users and movies.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let userBias = tf.layers.embedding({inputDim: nUsers, inputLength: 1, outputDim: 1});\n\nlet movieBias = tf.layers.embedding({inputDim: nMovies, inputLength: 1, outputDim: 1});\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["### Define architecture\n\nWith the main layers defined, we can start connecting the layers to define the model architecture. The architecture of a Collaboratorive filtering network looks roughly as shown in the output of the next cell."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h3>Define architecture</h3>\n<p>With the main layers defined, we can start connecting the layers to define the model architecture. The architecture of a Collaboratorive filtering network looks roughly as shown in the output of the next cell.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let img = document.createElement(\"img\")\nimg.src = `https://g.gravizo.com/svg?\n  digraph G {\n    rankdir=\"BT\"\n    node [shape=box]\n    userInput -> userEmbedding\n    userInput -> userBias\n    movieInput -> movieEmbedding\n    movieInput -> movieBias\n    userEmbedding -> dotProduct\n    movieEmbedding -> dotProduct\n    dotProduct -> sum\n    userBias -> sum\n    movieBias -> sum\n    sum -> sigmoid\n }\n`\nimg"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Let us start connecting the layers according to the diagram. Keep in mind that it is common for machine learnig models that the input is at the bottom and the output is at the top of the diagram. Calling the `apply` method on a layer specifies the input for that layer.\n\nFirst up, we connect the embedding layers for the users and movies to the input layers of the model.\n\nSecondly, we compute a \"match score\" between the user and movie embeddings by using the dot product."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Let us start connecting the layers according to the diagram. Keep in mind that it is common for machine learnig models that the input is at the bottom and the output is at the top of the diagram. Calling the <code>apply</code> method on a layer specifies the input for that layer.</p>\n<p>First up, we connect the embedding layers for the users and movies to the input layers of the model.</p>\n<p>Secondly, we compute a &quot;match score&quot; between the user and movie embeddings by using the dot product.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let userOutput = userEmbedding.apply(userInput);\nlet movieOutput = movieEmbedding.apply(movieInput);\n\nlet dotUserMovie = tf.layers.dot({axes: -1}).apply([userOutput,movieOutput]);\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Let us then compute a per-user and per-movie bias, which we then add together with the computed \"match score\".\n\nFinally we pass the computed sum the a sigmoid activation function that scales the output into the `[0,1]` range."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Let us then compute a per-user and per-movie bias, which we then add together with the computed &quot;match score&quot;.</p>\n<p>Finally we pass the computed sum the a sigmoid activation function that scales the output into the <code>[0,1]</code> range.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let userBiasOutput = userBias.apply(userInput);\nlet movieBiasOutput = movieBias.apply(movieInput);\n\nlet sum = tf.layers.add().apply([dotUserMovie, userBiasOutput, movieBiasOutput]);\n\nlet output = tf.layers.activation({activation: \"sigmoid\"}).apply(tf.layers.flatten().apply(sum))\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["### Create model\n\nWith all layers connected, we can create the model by specifying its inputs and outputs."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h3>Create model</h3>\n<p>With all layers connected, we can create the model by specifying its inputs and outputs.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let model = tf.model({inputs: [userInput,movieInput], outputs: output});\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["For the trainging of the model we use a Binary Crossentropy loss function and an Adam optimizer with a learnign rate of `0.005`."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>For the trainging of the model we use a Binary Crossentropy loss function and an Adam optimizer with a learnign rate of <code>0.005</code>.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["model.compile({optimizer: tf.train.adam(0.005), loss: \"binaryCrossentropy\", metrics: [\"accuracy\"]})\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Tain model\n\nBefore we train the model, let's create a plot where we can monitor the training progress."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Tain model</h2>\n<p>Before we train the model, let's create a plot where we can monitor the training progress.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let monitor = document.createElement(\"div\")\nmonitor.id = \"monitor\"\nmonitor"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let lossData = {x: [], y: [], type: \"scatter\", mode: \"lines\", name: \"loss\"}\nlet valLossData = {x: [], y: [], type: \"scatter\", mode: \"lines\", name: \"validation loss\"}\n\nplotly.newPlot(\"monitor\",[lossData, valLossData], {xaxis: {title: \"Epoch\"}, yaxis: {title: \"Loss function\"}})\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["The next cell starts the trainging process. For trainging it is very important to not only track the evolution of the loss function but also see how the loss function evolves on samples that are not used for training. These samples are called validation samples. By specifying the `validationSplit: 0.9`, we tell the algorithm that we want to keep 10% of the samples to compute the validation loss function.\n\nBe aware that executing the next cell might take a couple of minutes."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>The next cell starts the trainging process. For trainging it is very important to not only track the evolution of the loss function but also see how the loss function evolves on samples that are not used for training. These samples are called validation samples. By specifying the <code>validationSplit: 0.9</code>, we tell the algorithm that we want to keep 10% of the samples to compute the validation loss function.</p>\n<p>Be aware that executing the next cell might take a couple of minutes.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["await model.fit(x, y, {\n  epochs: 6,\n  validationSplit: 0.9,\n  callbacks: [{onEpochEnd: (epoch, logs) => {\n    lossData.x.push(epoch)\n    lossData.y.push(logs.loss)\n    valLossData.x.push(epoch)\n    valLossData.y.push(logs.val_loss)\n    plotly.redraw(\"monitor\")\n    return;\n  }}]\n});\n\n\"Done training\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["## Show top 10 movie recommendations\n\nGreat, we have trained our model. Let us now see if we can get some movie recommendations for the some of the users. Of course we only want to recommend movies to them that they haven't already watched.\n\nTo handle the movie data, we create a dataframe for the movies."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Show top 10 movie recommendations</h2>\n<p>Great, we have trained our model. Let us now see if we can get some movie recommendations for the some of the users. Of course we only want to recommend movies to them that they haven't already watched.</p>\n<p>To handle the movie data, we create a dataframe for the movies.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let movie_df = new DataFrame(movies);\n\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Then, we pick one of the users by random."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Then, we pick one of the users by random.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let userId = Math.floor(Math.random() * nUsers);\n\nuserId"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Let's see which movies they watched and how they ranked those movies."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Let's see which movies they watched and how they ranked those movies.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let watchedMovies = df.query(df[\"user\"].eq(userId));\n\nwatchedMovies"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["But they are probably more interested in movies they haven't watched. Which are still quite many."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>But they are probably more interested in movies they haven't watched. Which are still quite many.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let notWatchedMovies = df.drop({index: watchedMovies.index, inplace: false})[\"movie\"].unique();\n\nlet notWatchedCount = notWatchedMovies.count();\n\nnotWatchedCount"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Since we now know the ids of the not-watched movies, we have to put them into a form that we can pass to the model to make the prediction. So we convert the movie indices into a tensor and create a tensor with multiple entries of the users index."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Since we now know the ids of the not-watched movies, we have to put them into a form that we can pass to the model to make the prediction. So we convert the movie indices into a tensor and create a tensor with multiple entries of the users index.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let movieTensor = notWatchedMovies.tensor.expandDims(1);\n\nlet userTensor = tf.fill([notWatchedCount,1],userId);\n\nlet xPred = [userTensor, movieTensor];"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Let's get the predicted ratings of that user for all movies that they haven't watched."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Let's get the predicted ratings of that user for all movies that they haven't watched.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let pred = model.predict(xPred)\n\nlet pred_df = new DataFrame(model.predict(xPred))\n\npred_df.toString()"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Now we can see which movies they probably rate highest."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Now we can see which movies they probably rate highest.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let bestMovies = pred_df[\"0\"].argSort({ascending: false}).values.slice(0,10)\n\nbestMovies"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["And display their names."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>And display their names.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["bestMovies.map(x => {\n  let movieId = df.query(df[\"movie\"].eq(x))[\"movieId\"].iloc([0]).values[0];\n  return movie_df.query(movie_df[\"movieId\"].eq(movieId))\n})"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]}]}
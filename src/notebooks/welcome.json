{"nbformat":4,"nbformat_minor":0,"metadata":{"kernel_info":{"name":"Weblab"},"language_info":{"name":"javascript"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["![landing](/landing.svg)"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p><img src=\"/landing.svg\" alt=\"landing\" /></p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["![interactive](/Interactive.svg) ![compatible](/Compatible.svg) ![javascript](/Javascript.svg)"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p><img src=\"/Interactive.svg\" alt=\"interactive\" /> <img src=\"/Compatible.svg\" alt=\"compatible\" /> <img src=\"/Javascript.svg\" alt=\"javascript\" /></p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["# Try it yourself!\n\nThe document you are reading is not a common website but an interactive programming environment called a \"notebook\". It is a collection of **interactive cells** that can be freely created and edited. There are two types of cells, code and markdown cells.\n\nThe following cell is a **code cell**. Code cells let you write and evaluate Javascript code. You can evaluate the cell by pressing \"Shift + Enter\" or the \"Run\" button."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h1>Try it yourself!</h1>\n<p>The document you are reading is not a common website but an interactive programming environment called a &quot;notebook&quot;. It is a collection of <strong>interactive cells</strong> that can be freely created and edited. There are two types of cells, code and markdown cells.</p>\n<p>The following cell is a <strong>code cell</strong>. Code cells let you write and evaluate Javascript code. You can evaluate the cell by pressing &quot;Shift + Enter&quot; or the &quot;Run&quot; button.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["// Press \"Shift + Enter\" to evaluate the cell\n\nvar message = \"Hello\" + \" World\"\n\nmessage"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["__Congratulations!__ You just ran your first little program using Weblab. As you can see, Weblab displays the last expression in a code cell as its output. To learn more about code and markdown cells check out the [Getting Started](/documentation/getting_started) guide."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p><strong>Congratulations!</strong> You just ran your first little program using Weblab. As you can see, Weblab displays the last expression in a code cell as its output. To learn more about code and markdown cells check out the <a href=\"/documentation/getting_started\">Getting Started</a> guide.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["# Machine learning\n\nOne advantage of using a notebook to run your code, is that you can immediatly visualize its output. This is particularly handy when you are processing data, for example for a machine learning application. To see how this works we will have a look at an [example of the tensorflow project](https://codelabs.developers.google.com/codelabs/tensorflowjs-teachablemachine-codelab/index.html) where we use a pre-trained neural network to classify images."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h1>Machine learning</h1>\n<p>One advantage of using a notebook to run your code, is that you can immediatly visualize its output. This is particularly handy when you are processing data, for example for a machine learning application. To see how this works we will have a look at an <a href=\"https://codelabs.developers.google.com/codelabs/tensorflowjs-teachablemachine-codelab/index.html\">example of the tensorflow project</a> where we use a pre-trained neural network to classify images.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["## Image classification with a pre-trained neural network\n\nThe goal of this example is to **classify images** that are taken from either the internet or captured by the webcam.\nNeural networks are great for image classification but their training requires a lot of data and computational effort.\nLuckily we can skip the training process and use an existing, pre-trained neural network called [MobileNet](https://arxiv.org/abs/1801.04381) for our classification.\n\nTo use the model we import the `tensorflowjs` library and the `mobilenet` model as follows:"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h2>Image classification with a pre-trained neural network</h2>\n<p>The goal of this example is to <strong>classify images</strong> that are taken from either the internet or captured by the webcam.\nNeural networks are great for image classification but their training requires a lot of data and computational effort.\nLuckily we can skip the training process and use an existing, pre-trained neural network called <a href=\"https://arxiv.org/abs/1801.04381\">MobileNet</a> for our classification.</p>\n<p>To use the model we import the <code>tensorflowjs</code> library and the <code>mobilenet</code> model as follows:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["import * as tf from \"@tensorflow/tfjs\";\nimport * as mobilenet from \"@tensorflow-models/mobilenet\";\n\nmobilenet.version"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["In addition, the contents of the model need to be loaded in order to use it. This is done in the following cell.\nBe aware that the await keyword is required to obtain the results from [asynchronous functions](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await)."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>In addition, the contents of the model need to be loaded in order to use it. This is done in the following cell.\nBe aware that the await keyword is required to obtain the results from <a href=\"https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await\">asynchronous functions</a>.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let net = await mobilenet.load();\n\"Done\""],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["To do the classification we first need an image. We can load an image from a remote url by creating an image element in our notebook."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>To do the classification we first need an image. We can load an image from a remote url by creating an image element in our notebook.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let img = document.createElement(\"img\");\nimg.height = 224\nimg.width = 224\nimg.src = 'https://i.imgur.com/JlUvsxa.jpg'\nimg.crossOrigin = 'anonymous'\nimg"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Okay, the image looks obvious. Let's see how the neural network performs! For that we simply pass the image element to the `mobilenet` classification function."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Okay, the image looks obvious. Let's see how the neural network performs! For that we simply pass the image element to the <code>mobilenet</code> classification function.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["await net.classify(img);"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["The classification seems really good. You actually need to be a dog expert to check whether it's right."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>The classification seems really good. You actually need to be a dog expert to check whether it's right.</p>\n"}}]},{"cell_type":"markdown","metadata":{},"source":["### Classify webcam pictures\n\nLet's make it even more interesting. For the next part we classify pictures that we take with your webcam. If you don't want to activate your webcam you can just leave this part.\n\nTo use the webcam, we create a webcam object as follows:"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<h3>Classify webcam pictures</h3>\n<p>Let's make it even more interesting. For the next part we classify pictures that we take with your webcam. If you don't want to activate your webcam you can just leave this part.</p>\n<p>To use the webcam, we create a webcam object as follows:</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let video = document.createElement(\"video\");\nvideo.id=\"webcam\";\nvideo.autoplay = true;\nvideo.muted = true;\nvideo.playsinline = true;\nvideo.width = 224;\nvideo.height = 224;\nlet webcam = await tf.data.webcam(video);"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["Everytime the next cell is evaluated the webcam will take a picture which is then classified. So try evaluating the next cell while holding some object like a water bottle, cell phone or keyboard in front of your camera."],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>Everytime the next cell is evaluated the webcam will take a picture which is then classified. So try evaluating the next cell while holding some object like a water bottle, cell phone or keyboard in front of your camera.</p>\n"}}]},{"cell_type":"code","execution_count":0,"metadata":{},"source":["let webcam_image = await webcam.capture();\nawait net.classify(webcam_image);"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":""}}]},{"cell_type":"markdown","metadata":{},"source":["If you are interested in more elaborate examples, these could be of interest:\n\n- [Making predictions from 2D data](/documentation/guides_and_tutorials/regression_training)\n- [Image classification with Transfer Learning and MobileNet v2](/documentation/guides_and_tutorials/transfer_learning_mobilenet)\n- [Finetuning an ALBERT encoder for text classification](/documentation/guides_and_tutorials/albert_finetuning)\n- [Collaborative filtering for movie recommendations](/documentation/guides_and_tutorials/movie_recommendation)\n- [Building a face recognition pipeline](/documentation/guides_and_tutorials/face_recognition)\n- [Data processing with Danfo.js](/documentation/guides_and_tutorials/danfo)"],"outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<p>If you are interested in more elaborate examples, these could be of interest:</p>\n<ul>\n<li><a href=\"/documentation/guides_and_tutorials/regression_training\">Making predictions from 2D data</a></li>\n<li><a href=\"/documentation/guides_and_tutorials/transfer_learning_mobilenet\">Image classification with Transfer Learning and MobileNet v2</a></li>\n<li><a href=\"/documentation/guides_and_tutorials/albert_finetuning\">Finetuning an ALBERT encoder for text classification</a></li>\n<li><a href=\"/documentation/guides_and_tutorials/movie_recommendation\">Collaborative filtering for movie recommendations</a></li>\n<li><a href=\"/documentation/guides_and_tutorials/face_recognition\">Building a face recognition pipeline</a></li>\n<li><a href=\"/documentation/guides_and_tutorials/danfo\">Data processing with Danfo.js</a></li>\n</ul>\n"}}]}]}